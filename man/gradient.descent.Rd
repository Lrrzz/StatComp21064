% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/StatCompR.R
\name{gradient.descent}
\alias{gradient.descent}
\title{Gradient descent method to find the coefficients of linear regression equation}
\usage{
gradient.descent(
  x,
  y,
  epsilon = 1e-14,
  maxit = 1000,
  stepsize = 0.001,
  alpha = 0.25,
  b = 0.8,
  stepmethod = "backtracking",
  verbose = TRUE,
  plotLoss = TRUE
)
}
\arguments{
\item{x}{a m*n data matrix}

\item{y}{observations size of m*1}

\item{epsilon}{termination condition, difference between the coefs of two consecutive iters}

\item{maxit}{the maximum number of iterations, default is 1000}

\item{stepsize}{just stepsize, must smaller than 1e-3, default is 1e-3}

\item{alpha}{parameter in the backtracking method, should in (0,0.5), default is 0.25}

\item{b}{parameter in the backtracking method, should in (0,1), default is 0.8}

\item{stepmethod}{optional "backtracking" or "fixed", default is "backtracking"}

\item{verbose}{whether to print out iterations, default is "TRUE"}

\item{plotLoss}{whether to plot loss, default is "TRUE"}
}
\value{
a list contains coefficients,RSE and number of iterations
}
\description{
Gradient descent method to find the coefficients of linear regression equation
}
\examples{
\dontrun{
n=100
x1<-rnorm(n)
x2<-rnorm(n)
y=1+0.5*x1+x2+rnorm(n,sd=0.1)
x<-cbind(x1,x2)
gradient.descent(x,y)
}
}
